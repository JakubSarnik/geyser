We base our implementation mainly on Efficient implementation of property
directed reachability (Een, Mischenko, Brayton) and Comparing different
variants of the IC3 algorithm for hardware model checking (Griggio, Roveri).
We have also taken a look at the source code of IC3Ref (Bradley), although our
overall design is much closer to Een et al. than to Bradley. Note that the
method of generalizing predecessors was taken from Incremental formal
verification of hardware (Chockler et al.), and the approach to inductive
generalization of blocked cubes from Better generalization in ic3 (Hassan,
Bradley, Somenzi).

Given a transition system S = <X, Y, I(X), T(X, Y, X')> and an error formula
E(X, Y) [describing that input Y in state X is bad; note that the error formula
might depend on Y in Aiger], we store a trace

  F_0, F_1, ..., F_k

where each F_i is a set of cubes blocked at step i, but not at step i + 1. Note
that we can reconstruct the original meaning of the trace

  R_0, R_1, ..., R_k

in IC3 by

  R_i = -F_i /\ -F_{i + 1} /\ ... /\ -F_k
  (and R_0 = I).

The trace is implemented as a vector storing F_0, ..., F_k in order. We also
store activation variables for each frame in vector Act, and the solver is
informed about the contents of the frames as follows: Whenever we add a new
cube c to F_i, the clause -c_i (-c activated by Act_i) is added to the solver.
We can then solve with R_i activated by assuming literals Act_i through Act_k.

In order to do everything using a single solver, we also need to variously
activate or deactivate formulas T and E. Thus, we also have activation
variables ActT and ActE. The solver is initially loaded by both formulas
activated by their respective variables.

The pseudocode is given below. Note several conventions:
  - |X| is the size of the collection X
  - for a given formula f, f' is f.map( fun lit => lit.prime() )
  - -f is the negation of f
  - etc.


pdr() -> result:

  # Create (empty) F_0 at the start of F (i.e. F = [F_0]).
  push_frame()

  # Note that k is |F| - 1.

  # Fill the solver by the transition system's CNF specification. Note that the
  # first frame is handled separately - F[ 0 ] is kept empty and Act[ 0 ]
  # activates the initial formula.

  sat_add_formula( I.activated_by( Act[ 0 ] ) )
  sat_add_formula( T.activated_by( ActT ) )
  sat_add_formula( E.activated_by( ActE ) )

  loop:

    # This implements SAT( R[ k ] /\ E ) query.
    while is_sat_assuming( Act[ k ], ActE ):
      s = sat_get_model().filter( is_state_variable )

      if solve_obligation( < s, k > ) == counterexample:
        # This needs to be done with some additional bookkeeping...
        # (see the state pool in IC3ref).

        return counterexample

    push_frame() # Create (empty) F_{k + 1}.

    if propagate() == invariant_found:
      return ok


solve_obligation( < s, k' > : cube * int ) -> result:
  assert 0 <= k' <= k

  # Minimum priority queue of proof obligations, ordered by frame.
  Q = minimum_queue[ cube * int ]()
  Q.add( < s, k' > )

  while ( |Q| > 0 ):
    < c, i > = Q.pop_minimum()

    if i == 0:
      return counterexample # We have backtraced to an initial state!

    # If we have already seen this cube, do not return to it.
    if is_already_blocked( < c, i > ):
      continue

    # Note that at this point, c is guaranteed not to intersect with the
    # initial states.

    # This implements SAT( R[ i - 1 ] /\ -c /\ T /\ c' ) query. Note that
    # sat_constrain adds the clause -c (but only a single clause) into the SAT
    # solver's context with the same lifetime as assumed literals (i.e. the
    # clause will disappear once the query is finished). This API is provided
    # by CaDiCaL.

    sat_constrain( -c )
    if is_sat_assuming( ActT, literals( c' ), Act[ i - 1 ], ..., Act[ k ] ):

      # c has a predecessor d in R[ i - 1 ], generalize a full cube of d to
      # a shorter cube.
      d = generalize_predecessor( c )

      # Focus now on blocking d one step closer to the initial states.
      Q.add( < d, i - 1 > )

      # After that is done, return back to c, try a different predecessor.
      Q.add( < c, i > )

    else:
      # There is no predecessor in R[ i - 1 ] of any state in c
      # Generalize cube c to block more states.

      # TODO: Not generalize_inductive( c, i - 1 )??? And don't we want to
      #       change the level from i to some general j? See the following
      #       comment...
      d = generalize_inductive( c, i )

      # Note that Een et al.'s generalization is quite a bit more involved here
      # and we need to access the unsat core of the SAT call. There,
      # generalize_inductive returns < d, j >, and the code would look
      # differently:
      #
      #   add_blocked_at( d, j )
      #
      #   if i < k:
      #     Q.add( < c, j > )

      add_blocked_at( d, i )

  return still_safe;


push_frame():
  assert |F| = |Act|

  F.push_back()
  Act.push_back( make_variable() )


propagate() -> propagate_result:
  for i in 1 .. ( k - 1 ):
    for c in F[ i ]:

      # We push a blocked cube c from F[ i ] to F[ i + 1 ] if it is still
      # blocked in that frame, i.e. if SAT( R[ i ] /\ -c /\ T /\ c' )
      # is false. However, we actually know that c is already blocked
      # at i (i.e. the clause -c will be activated by Act[ i ]), so we only
      # have to ask whether SAT( R[ i ] /\ T /\ c' ) is false.

      if not is_sat_assuming( ActT, literals( c' ), Act[ i ], ..., Act[ k ] ):

        # Beware here that add_blocked_at will actually remove the clause c
        # from F[ i ] as subsumed (by itself). Depending on implementation,
        # this can, e.g., reorder F[ i ] or do all sort of things with it,
        # and the implementation of iteration through F[ i ] must react to
        # this.

        add_blocked_at( c, i + 1 )

    # After propagating the cubes from F[ i ], it might happen that all the
    # cubes that held in F[ i ] also hold in F[ i + 1 ], i.e. every cube
    # in F[ i ] was added to F[ i + 1 ] and by subsumption removed from F[ i ],
    # leaving F[ i ] empty. This indicates that R[ i ] = R[ i + 1 ], i.e. we
    # have found our inductive invariant.

    if |F[ i ]| = 0:
      return invariant_found

  return invariant_not_found


is_already_blocked( < c, i > : cube * int ) -> bool:
  assert 1 <= i <= k

  # We want to check whether R[ i ] |= -c. If there is a cube d between F[ i ]
  # and F[ k ] that subsumes c (which guarantees c |= d), the result is
  # immediate (since R[ i ] |= -d, -d |= -c).

  for j in i .. k:
    for d in F[ j ]:
      if subsumes( d, c ):
        return true

  # Only if this fails, we perform a more expensive SAT query
  # SAT( R[ i ] /\ c ). This formula is satisfiable if and only if the
  # entailment R[ i ] |= -c fails.

  return not is_sat_assuming( literals( c ), Act[ i ], ..., Act[ k ] )


add_blocked_at( c : cube, i : int ):
  assert 1 <= i <= k

  # First add the cube c to F[ i ]. However, our trace can at this point
  # contain "strictly weaker information" which is easy to detect and remove:
  # If we already have a cube d in some F[ j ] (j <= i) that is subsumed by c,
  # there is no reason to keep it, since c blocks at least as many states as d.

  for j in 1 .. k:
    for d in F[ j ]:
      if subsumes( c, d ):
        F[ j ].remove( d )

  F[ i ].push_cube( c )

  # Now add the cube also to the solver. We cannot remove the subsumed clauses
  # in the solver, but we can reset the solver periodically (once every X SAT
  # queries, Griggio et al. suggest about 5000 but in a slightly different
  # setting -- they also want to get rid of unneeded activation literals).

  sat_add_clause( ( -c ).activated_by( Act[ i ] ) )


subsumes( c : cube, d : cube ) : bool

  # A cube c subsumes d if literals( c ) is a subset of literals( d ). For
  # example, A /\ -B subsumes A /\ -B /\ C. Note that if c subsumes d, we have
  # d |= c. Beware of the difference between this and the more common
  # subsumption of clauses c and d, which is defined in the same way (e.g.
  # A \/ -B subsumes A \/ -B \/ C), but guarantees c |= d instead!

  if |literals( c )| > |literals( d )|:
    return false

  for l in literals( c ):
    if not literals( d ).contains( l ):
      return false

  return true


generalize_predecessor( s : cube ) -> cube:
  assert s.all( fun lit => var( lit ).is_state_variable )

  # We found that s is a cube satisfying R[ i - 1 ] /\ -s /\ T /\ s' for some
  # i, now we want to get a predecessor cube d to s. While just fetching all
  # the state variables from the model of the formula above would give us a
  # cube representing precisely one predecessor d in R[ i - 1 ], we want to
  # generalize to more than a single state by returning a cube that does not
  # contain all state variables.

  # Note that this function must be called before a different sat call is made.
  ins = sat_get_model().filter( is_input_variable )
  p = sat_get_model().filter( is_state_variable )

  loop:

    # Query SAT( T /\ ins /\ p /\ -s' ). We know this is unsatisfiable, since
    # ins /\ p gives us exactly the transition from the predecessor of s found
    # by the SAT query performed before calling this function. This property
    # is then maintained by the loop.

    sat_constrain( -s' )
    b = is_sat_assuming( ActT, ins, p )

    assert not b

    s = sat_get_core().filter( fun lit => p.contains( lit ) )

    # We asked for all the literals in p that were needed to determine that
    # T /\ ins /\ p /\ -s' is not satisfiable. If they were all needed, we
    # cannot shrink p any further. Otherwise, throw away all those that weren't
    # necessary and check SAT( T /\ ins /\ p /\ -s' ) again in a new iteration.
    # Note that by this must still be unsatisfiable (we have, after all, left
    # in all the p literals that were used in the very proof of that), which
    # guarantees the invariant mentioned above.

    # Additionally, this loop must ultimately finish by returning p, since in
    # every iteration, we either shrink p by at least one literal, or not
    # shrink it and stop.

    if s == p:
      return p
    else:
      p = s


generalize_inductive( c : cube, i : int ) -> cube:
  assert 1 <= i <= k

  # Clause -c has been found to be inductive relative to R[ i - 1 ], i.e. the
  # formula R[ i - 1 ] /\ -c /\ T /\ c' was found to be unsatisfiable in
  # solve_obligation (that is, there is no predecessor state of any state in c
  # in the frame R[ i - 1 ]). (Note that the inductivity comes from the fact
  # that the formula is unsatisfiable iff R[ i - 1 ] /\ -c /\ T |= -c' holds.)
  # We could now just add -c to F[ i ], but we want to generalize the clause
  # to contain more states by dropping some literals from it.

  return -generalize_clause( -c, i, 1 )


generalize_clause( c : clause, i : int, level : int ) -> clause:
  required = set[ literal ]()

  for l in literals( c ):
    d = c.filter( fun lit => lit /= l )
    success, d = down( d, i, level, required )

    if success:
      c = d
    else:
      required.insert( l )

  return c


down( c : clause, i : int, level : int, req : set[ literal ] )
  -> bool * clause:

  assert 0 <= i <= k

  # We use two heuristically chosen configuration parameters in this function:
  # - max_ctgs
  # - max_level
  # Bradley suggests using values max_ctgs = 3, max_level = 1.

  ctgs = 0

  loop:
    # SAT( I /\ -c )? If so, our c intersects the initial states and as such
    # cannot be (relatively) inductive anymore.

    if is_sat_assuming( Act[ 0 ], literals( -c ) ):
      return false, c

    # SAT( R[ i ] /\ c /\ T /\ -c' )? If not, c is inductive relative to R[ i ].

    sat_constrain( c )
    if not is_sat_assuming( ActT, literals( -c' ), Act[ i ], ..., Act[ k ] ):
      d = clause( sat_get_core()
                  .filter( fun lit => is_primed_variable( var( lit ) ) )
                  .map( unprime ) )

      # Add literals until we have a guarantee that clause d doesn't intersect
      # the initial states.

      sat_constrain( d )
      while is_sat_assuming( Act[ 0 ] ):

        # Griggio has here simply "pick any literal"
        l = literals( c ).set_minus( literals( d ) ).first()
        d.insert( d )

        sat_constrain( d )

      return true, d

    # We don't want to spend too much time on addressing CTGs (which happens
    # when this function is called recursively, see below).

    if level > max_level:
      return false, c

    # Here we know that c is not inductive relative to R[ i ], i.e. it has
    # a predecessor in R[ i ].

    s = generalize_predecessor( -c )

    # SAT( I /\ s )?
    q1 = is_sat_assuming( Act[ 0 ], literals( s ) )

    # SAT( R[ i - 1 ] /\ -s /\ T /\ s' )
    sat_constrain( -s )
    q2 = is_sat_assuming( ActT, literals( s' ), Act[ i - 1 ], ... Act[ k ] )

    # Note that if both q1 and q2 are false, the predecessor s is inductive
    # relative to R[ i - 1 ].

    if ctgs < max_ctgs and i > 0 and not q1 and not q2:
      ctgs = ctgs + 1
      j = i

      # While we don't have s inductive relative to F[ j ]...
      # (i.e. while not SAT( R[ j ] /\ -s /\ T /\ s' ))

      sat_constrain( -s )
      while not is_sat_assuming( ActT, literals( s' ), Act[ j ], ..., Act[ k ] ):
        assert j <= k

        j = j + 1
        sat_constrain( -s )

      _, d = generalise_clause( -s, j - 1, level + 1 )
      add_blocked_at( -d, j )

    else:
      ctgs = 0
      sz = |( literals( c ).set_minus( literals( -s ) ) ).set_intersect( req )|

      if sz > 0:
        return false, c

      c = c.set_intersect( -s )


TODO:
  - How to efficiently represent cubes? If they are unsorted literal vectors,
    subsumption check is necessarily quadratic. If they are sorted literal
    vectors, subsumption can be checked in linear time, but cannot this
    interact negatively with solver heuristics?
  - How to efficiently represent sets of cubes? Investigate vectors vs rb-trees
    vs hash tables.
  - When to reset the solver? Our only reason is probably to remove subsumed
    clauses, we do not recycle any activation literals.