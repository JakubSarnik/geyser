We base our implementation mainly on Efficient Implementation of Property
Directed Reachability (Een, Mischenko, Brayton) and Comparing Different
Variants of the IC3 Algorithm for Hardware Model Checking (Griggio, Roveri).

Given a transition system S = <X, Y, I(X), T(X, Y, X')> and an error formula
E(X, Y) [describing that input Y in state X is bad; note that the error formula
might depend on Y in Aiger], we store a trace

  F_0, F_1, ..., F_k

where each F_i is a set of cubes blocked at step i, but not at step i + 1. Note
that we can reconstruct the original meaning of the trace

  R_0, R_1, ..., R_k

in IC3 by

  R_i = -F_i /\ -F_{i + 1} /\ ... /\ -F_k
  (and R_0 = I).

The trace is implemented as a vector storing F_0, ..., F_k in order. We also
store activation variables for each frame in vector Act, and the solver is
informed about the contents of the frames as follows: Whenever we add a new
cube c to F_i, the clause -c_i (-c activated by Act_i) is added to the solver.
Since solving under Act_i means we want to have all the clauses from i up to
k active (i.e. Act_i activates R[ i ], not just F[ i ]), we add an implication
Act_k -> Act_{k + 1} to the solver whenever we push a new frame F_k.

In order to do everything using a single solver, we also need to variously
activate or deactivate formulas T and E. Thus, we also have activation
variables ActT and ActE. The solver is initially loaded by both formulas
activated by their respective variables.

The pseudocode is as follows:

pdr() -> result:
  # Create (empty) F_0 at the start of F (i.e. F = [F_0]). push_frame expects
  # Act array to be one step in front so that Act forward implication can be
  # added.

  Act.push_back( make_variable() )
  push_frame()

  # Note that k is |F| - 1.

  # Fill the solver by the transition system's CNF specification. Note that the
  # first frame is handled separately - F[ 0 ] is kept empty and Act[ 0 ]
  # activates the initial formula.

  assert_formula( I.activated_by( Act[ 0 ] ) )
  assert_formula( T.activated_by( ActT ) )
  assert_formula( E.activated_by( ActE ) )

  loop:
    # This implements SAT( R[ k ] /\ E ) query.
    while sat_assuming( Act[ k ], ActE ):

      # Read all (non-primed) state variables from the solver.
      s = model( R[k] /\ E )

      if solve_obligation( < s, k > ) == counterexample:
        # This needs to be done with some additional bookkeeping...
        # (see the state pool in IC3ref).

        return counterexample

    push_frame() # Create (empty) F_{k + 1}.

    if propagate() == invariant_found:
      return ok


solve_obligation( < s, k' > : cube * int ) -> result:
  assert k' <= k

  # Minimum priority queue of proof obligations, ordered by frame.
  Q = minimum_queue()
  Q.add( < s, k' > )

  while ( |Q| > 0 ):
    < c, i > = Q.pop_minimum()

    if i == 0:
      return counterexample # We have backtraced to an initial state!

    # If we have already seen this cube, do not return to it.
    if is_already_blocked( < c, i > ):
      continue

    # Note that at this point, c is guaranteed not to intersect with the
    # initial states.

    # This implements SAT( R[ i - 1 ] /\ -c /\ T /\ c' ) query. Note that
    # constrain adds the clause -c (but only a single clause) into the SAT
    # solvers' context with the same lifetime as activation literals (i.e.
    # the clause will disappear once the query is finished). This API is
    # provided by CaDiCaL.

    constrain( -c )
    if sat_assuming( Act[ i - 1 ], ActT, literals( c' ) ):

      # c has a predecessor d in R[ i - 1 ], implement by reading all the
      # non-primed state variables from the solver.

      d = model( R[ i - 1 ] /\ -c /\ T /\ c' )

      # Generalize a full model to a shorter cube.
      e = generalize_predecessor( d )

      # Focus now on blocking e one step closer to the initial states.
      Q.add( < e, i - 1 > )

      # After that is done, return back to c, try a different predecessor.
      Q.add( < c, i > )

    else:
      # There is no predecessor in R[ i - 1 ] of any state in c
      # Generalize cube c to block more states.

      < d, j > = generalize_inductive( c, i )

      # Note that Een et al.'s generalization is quite a bit more involved
      # here, and we need to access the unsat core of the SAT call.

      add_blocked_at( d, j )

      # This is not necessary according to Een et al., but it apparently
      # improves performance.
      # TODO: Investigate

      if i < k && j != inf:
        Q.add( < c, j > )


push_frame():
  assert |F| + 1 = |Act|

  F.push_back()
  Act.push_back( make_variable() )

  assert |Act| = k + 1

  # Add an implication guaranteeing that enabling frame F_i in the solver
  # enables F_i, F_{i + 1}, ..., F_k.

  assert_clause( -Act[ k ] \/ Act[ k + 1 ] )


propagate():
  for i in 1 .. ( k - 1 ):
    # TODO: We want to call add_blocked_at, but this will change the latter
    #       parts of the trace!


is_already_blocked( < c, i > : cube * int ) -> bool:
  assert i <= k

  # We first check whether all the states in c have already been blocked in
  # R[ i ] (that is, whether they have been blocked somewhere between F[ i ]
  # and F[ k ]) by checking for a simple syntactic subsumption of the cubes...

  for j in i .. k:
    for d in F[ j ]:
      if subsumes( d, c ):
        return true

  # ... only if this fails, we perform a more expensive SAT query
  # SAT( R[ i ] /\ c ). This formula is satisfiable if and only if the cube
  # c has non-empty intersection of states with R[ i ], i.e. when it hasn't
  # been blocked yet.

  return not sat_assuming( Act[ i ], literals( c ) )


add_blocked_at( c : cube, i : int ):
  assert i <= k

  # First add the cube c to F[ i ]. However, our trace can at this point
  # contain "strictly weaker information" which is easy to detect and remove:
  # If we already have a cube d in some F[ j ] (j <= i) that is subsumed by c,
  # there is no reason to keep it.

  for j in 1 .. k:
    for d in F[ j ]:
      if subsumes( c, d ):
        F[ j ].remove( d )

  F[ i ].push_cube( c )

  # Now add the cube also to the solver. We cannot remove the subsumed clauses
  # in the solver, but we can reset the solver periodically (once every X SAT
  # queries, Griggio et al. suggest about 5000 but in a slightly different
  # setting -- they also want to get rid of unneeded activation literals).

  assert_clause( ( -c ).activated_by( Act[ i ] ) )


subsumes( c : cube, d : cube ) : bool
  # A simple and syntactic (thus very conservative) check whether c |= d. This
  # holds iff all the literals in d are also in c with the same polarity.

  for l in literals( d ):
    if not literals( c ).contains( l ):
      return false

  return true


generalize_predecessor( s : cube ) -> cube:
  # We found that c is a predecessor state (i.e. a full cube) of some other cube.
  # Generalize (e.g. using ternary simulation or a SAT based approach) to a
  # smaller cube.

  TODO


generalize_inductive( s : cube, i : int ) -> cube:
  TODO



TODO:
  - How to efficiently represent cubes? If they are unsorted literal vectors,
    subsumption check is necessarily quadratic. If they are sorted literal
    vectors, subsumption can be checked in linear time, but cannot this
    interact negatively with solver heuristics?
  - How to efficiently represent sets of cubes? Investigate vectors vs rb-trees
    vs hash tables.
  - When to reset the solver? Our only reason is probably to remove subsumed
    clauses, we do not recycle any activation literals.
  - Isn't it a bit more efficient to manually activate Act[ i ] .. Act[ k ]
    instead of adding all those Act[ i ] -> Act[ i + 1 ] implications?
    Probably yes, but investigate (also this allows us to have |F| = |Act|),
    so a bit less of ceremony.